# -*- coding: utf-8 -*-
"""Sentiment Analysis MLOps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EbL1MAAvN23miA2q7MUYk9l9P_0Bm8L0

# Import Package
"""

try:
  import colab
except:
  pass

"""Kode ini mencoba mengimpor modul colab dan jika gagal, akan meng-upgrade pip menggunakan pip install --upgrade pip, sambil menangani pengecualian tanpa melakukan apa-apa jika impor gagal."""


import tensorflow as tf
from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator, Transform, Trainer
from tfx.proto import example_gen_pb2
from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext
import os

"""Kode ini melakukan beberapa hal:

- Mengimpor TensorFlow: import tensorflow as tf mengimpor TensorFlow untuk digunakan dalam model machine learning.
- Mengimpor Komponen TFX: Mengimpor berbagai komponen dari TensorFlow Extended (TFX) yang digunakan untuk membangun pipeline ML:
  - CsvExampleGen: Komponen untuk membaca data dari file CSV.
  - StatisticsGen: Menghitung statistik dasar dari data.
  - SchemaGen: Menghasilkan skema data berdasarkan statistik.
  - ExampleValidator: Memvalidasi contoh data terhadap skema.
  - Transform: Mengaplikasikan transformasi pada data.
  - Trainer: Melatih model ML.
- Mengimpor Protobuf: from tfx.proto import example_gen_pb2 mengimpor definisi protobuf untuk konfigurasi ExampleGen.
- Mengimpor InteractiveContext: from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext mengimpor konteks interaktif untuk menjalankan pipeline TFX dalam mode interaktif.
- Mengimpor os: import os mengimpor modul os untuk operasi terkait sistem file, seperti manipulasi jalur file.

# Data Ingestion
"""

PIPELINE_NAME = "sentiment-pipeline"
SCHEMA_PIPELINE_NAME = "sentiment-tfdv-schema"

PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)

METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')

SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)

"""Kode ini mendefinisikan beberapa variabel yang digunakan untuk menyusun jalur direktori dalam pipeline machine learning:

1. **`PIPELINE_NAME`**: Menetapkan nama untuk pipeline sebagai `"sentiment-pipeline"`.

2. **`SCHEMA_PIPELINE_NAME`**: Menetapkan nama untuk pipeline schema yang akan digunakan dengan TensorFlow Data Validation (TFDV) sebagai `"sentiment-tfdv-schema"`.

3. **`PIPELINE_ROOT`**: Menetapkan jalur direktori dasar untuk pipeline yang digabungkan dari `'pipelines'` dan nama pipeline, menghasilkan jalur `'pipelines/sentiment-pipeline'`.

4. **`METADATA_PATH`**: Menetapkan jalur untuk basis data metadata pipeline yang digabungkan dari `'metadata'`, nama pipeline, dan `'metadata.db'`, menghasilkan jalur `'metadata/sentiment-pipeline/metadata.db'`.

5. **`SERVING_MODEL_DIR`**: Menetapkan jalur direktori untuk model yang disajikan yang digabungkan dari `'serving_model'` dan nama pipeline, menghasilkan jalur `'serving_model/sentiment-pipeline'`.
"""

DATA_ROOT = "data"

"""Variabel **`DATA_ROOT`** menetapkan jalur dasar untuk data, yaitu `"data"`. Jalur ini digunakan sebagai referensi utama untuk lokasi di mana data mentah atau file data disimpan dalam proyek."""

interactive_context = InteractiveContext(pipeline_root=PIPELINE_ROOT)

"""Kode ini membuat instance dari `InteractiveContext` dengan jalur dasar pipeline yang ditentukan oleh variabel `PIPELINE_ROOT`. `InteractiveContext` digunakan untuk menjalankan dan mengeksplorasi pipeline TFX dalam mode interaktif, yang berguna untuk pengembangan dan debugging pipeline secara langsung di lingkungan interaktif."""

output = example_gen_pb2.Output(
    split_config = example_gen_pb2.SplitConfig(splits=[
        example_gen_pb2.SplitConfig.Split(name="train", hash_buckets=8),
        example_gen_pb2.SplitConfig.Split(name="eval", hash_buckets=2)
    ])
)
example_gen = CsvExampleGen(input_base=DATA_ROOT, output_config=output)

"""Kode ini melakukan dua langkah utama:

1. **Menyusun Konfigurasi Output**:
   - `example_gen_pb2.Output` digunakan untuk menentukan bagaimana data harus dibagi. Dalam hal ini, data dibagi menjadi dua subset:
     - **"train"**: Untuk pelatihan model, dengan 8 bucket hash untuk distribusi data.
     - **"eval"**: Untuk evaluasi model, dengan 2 bucket hash.
   - `split_config` mengatur pembagian data, di mana setiap split (train dan eval) memiliki konfigurasi masing-masing dalam hal jumlah bucket hash yang akan digunakan.

2. **Membuat Instance `CsvExampleGen`**:
   - `CsvExampleGen` adalah komponen TFX yang digunakan untuk membaca data dari file CSV.
   - `input_base=DATA_ROOT` menunjukkan lokasi dasar di mana file CSV berada.
   - `output_config=output` menerapkan konfigurasi pembagian data yang telah ditentukan sebelumnya pada komponen `CsvExampleGen`.

Dengan konfigurasi ini, data CSV di `DATA_ROOT` akan dibaca dan dibagi menjadi subset train dan eval sesuai dengan pengaturan bucket hash yang telah ditentukan.
"""

interactive_context.run(example_gen)

"""Menjalankan example_gen, yang merupakan instansi dari CsvExampleGen, dalam konteks interaktif. Ini akan memproses file CSV yang terletak di DATA_ROOT, membagi data sesuai dengan konfigurasi output yang telah ditetapkan, dan menyimpan hasilnya dalam direktori pipeline yang ditentukan (PIPELINE_ROOT).

# Data Validation
"""

statistics_gen = StatisticsGen(
    examples=example_gen.outputs["examples"]
)


interactive_context.run(statistics_gen)

"""Kode ini melakukan dua langkah utama:

Membuat Instance StatisticsGen:

- StatisticsGen adalah komponen TFX yang menghitung statistik dasar dari data yang diberikan.
examples=example_gen.outputs["examples"] mengarahkan StatisticsGen untuk menggunakan output dari komponen CsvExampleGen yang sebelumnya dijalankan. Output ini adalah dataset yang telah dibagi menjadi subset yang sesuai.
- Menjalankan StatisticsGen: interactive_context.run(statistics_gen) menjalankan StatisticsGen dalam konteks interaktif. Ini akan menghitung statistik dari data yang diberikan dan menyimpan hasil statistik tersebut dalam direktori pipeline (PIPELINE_ROOT).
"""

interactive_context.show(statistics_gen.outputs["statistics"])

"""Perintah ini digunakan untuk menampilkan hasil output dari komponen StatisticsGen.

"""

schema_gen = SchemaGen(    statistics=statistics_gen.outputs["statistics"]
)
interactive_context.run(schema_gen)

"""Kode ini melakukan dua langkah utama:

1. **Membuat Instance `SchemaGen`**:
   - `SchemaGen` adalah komponen TFX yang menghasilkan skema data berdasarkan statistik yang dihitung oleh `StatisticsGen`.
   - `statistics=statistics_gen.outputs["statistics"]` mengarahkan `SchemaGen` untuk menggunakan output statistik dari komponen `StatisticsGen`.

2. **Menjalankan `SchemaGen`**:
   - `interactive_context.run(schema_gen)` menjalankan `SchemaGen` dalam konteks interaktif. Ini akan menghasilkan skema data dan menyimpannya dalam direktori pipeline (`PIPELINE_ROOT`).
"""

interactive_context.show(schema_gen.outputs["schema"])

"""Perintah ini digunakan untuk menampilkan hasil output dari komponen `SchemaGen`:

- **`interactive_context.show(schema_gen.outputs["schema"])`**: Menampilkan skema data yang dihasilkan oleh `SchemaGen`.
"""

example_validator = ExampleValidator(
    statistics=statistics_gen.outputs['statistics'],
    schema=schema_gen.outputs['schema']
)
interactive_context.run(example_validator)

"""Kode ini melakukan dua langkah utama:

1. **Membuat Instance `ExampleValidator`**:
   - `ExampleValidator` adalah komponen TFX yang memvalidasi data terhadap skema yang telah dihasilkan dan statistik yang telah dihitung.
   - `statistics=statistics_gen.outputs['statistics']` dan `schema=schema_gen.outputs['schema']` memberikan input statistik dan skema yang digunakan untuk memeriksa apakah data memenuhi aturan dan batasan yang ditetapkan oleh skema.

2. **Menjalankan `ExampleValidator`**:
   - `interactive_context.run(example_validator)` menjalankan `ExampleValidator` dalam konteks interaktif. Ini akan memeriksa data dan melaporkan masalah atau ketidaksesuaian antara data dan skema.
"""

interactive_context.show(example_validator.outputs['anomalies'])

"""Perintah ini digunakan untuk menampilkan hasil output dari komponen `ExampleValidator`:

- **`interactive_context.show(example_validator.outputs['anomalies'])`**: Menampilkan laporan tentang anomali atau ketidaksesuaian yang ditemukan oleh `ExampleValidator` antara data dan skema.

# Data Preprocessing
"""

TRANSFORM_MODULE_FILE = "sentiment_transform.py"

"""Variabel **`TRANSFORM_MODULE_FILE`** menetapkan nama file modul Python yang berisi fungsi transformasi data untuk pipeline TFX. Dalam hal ini, file yang dimaksud adalah `"sentiment_transform.py"`."""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile {TRANSFORM_MODULE_FILE}
# import tensorflow as tf
# 
# LABEL_KEY = "sentiment"
# FEATURE_KEY = "review"
# def transformed_name(key):
#     """Renaming transformed features"""
#     return key + "_xf"
# 
# def cleaningText(text):
#     text = tf.strings.regex_replace(text, r'@[A-Za-z0-9]+', '')
#     text = tf.strings.regex_replace(text, r'#[A-Za-z0-9]+', '')
#     text = tf.strings.regex_replace(text, r'RT[\s]', '')
#     text = tf.strings.regex_replace(text, r"http\S+", '')
#     text = tf.strings.regex_replace(text, r'[0-9]+', '')
#     text = tf.strings.regex_replace(text, r'[^\w\s]', '')
#     text = tf.strings.regex_replace(text, r'\n', ' ')
#     text = tf.strings.regex_replace(text, r'\s+', ' ')
#     text = tf.strings.strip(text)
# 
#     return text
# 
# def casefoldingText(text):
#     text = tf.strings.lower(text)
#     return text
# 
# def transform_text(text):
#     text = cleaningText(text)
#     text = casefoldingText(text)
#     return text
# 
# def preprocessing_fn(inputs):
#     """
#     Preprocess input features into transformed features
# 
#     Args:
#         inputs: map from feature keys to raw features.
# 
#     Return:
#         outputs: map from feature keys to transformed features.
#     """
# 
#     outputs = {}
# 
#     outputs[transformed_name(FEATURE_KEY)] = transform_text(inputs[FEATURE_KEY])
# 
#     outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)
# 
#     return outputs

"""File **`sentiment_transform.py`** berisi kode untuk melakukan transformasi data dalam pipeline TFX. Berikut adalah penjelasan fungsional dari kode ini:

1. **`transformed_name(key)`**:
   - Fungsi ini menambahkan suffix `"_xf"` pada nama kunci fitur untuk menandakan bahwa fitur tersebut telah ditransformasi.

2. **`cleaningText(text)`**:
   - Fungsi ini membersihkan teks dengan menghapus elemen seperti tag @, hashtag #, retweet indicators, URL, angka, karakter non-alfanumerik, baris baru, dan whitespace ekstra. Fungsi ini juga menghapus spasi yang berlebihan dan melakukan strip pada teks.

3. **`casefoldingText(text)`**:
   - Fungsi ini mengubah teks menjadi huruf kecil untuk memastikan konsistensi dalam analisis teks.

4. **`transform_text(text)`**:
   - Fungsi ini menggabungkan fungsi `cleaningText` dan `casefoldingText` untuk melakukan transformasi penuh pada teks.

5. **`preprocessing_fn(inputs)`**:
   - Fungsi ini adalah titik masuk utama untuk transformasi fitur dalam pipeline TFX.
   - `inputs` adalah map dari kunci fitur ke fitur mentah.
   - Fungsi ini mengaplikasikan transformasi pada fitur `FEATURE_KEY` (ulasan) dan mengubah tipe data `LABEL_KEY` (sentimen) menjadi `tf.int64`.
   - Hasil transformasi disimpan dalam map `outputs` dengan nama yang ditransformasi.

Kode ini mempersiapkan data mentah untuk digunakan dalam model machine learning dengan membersihkan dan memformat teks, serta memastikan label memiliki tipe data yang tepat.
"""

transform  = Transform(
    examples=example_gen.outputs['examples'],
    schema= schema_gen.outputs['schema'],
    module_file=os.path.abspath(TRANSFORM_MODULE_FILE)
)
interactive_context.run(transform)

"""Kode ini melakukan dua langkah utama:

1. **Membuat Instance `Transform`**:
   - `Transform` adalah komponen TFX yang menerapkan transformasi data pada dataset berdasarkan modul transformasi yang diberikan.
   - `examples=example_gen.outputs['examples']` memberikan dataset mentah dari komponen `CsvExampleGen` sebagai input untuk transformasi.
   - `schema=schema_gen.outputs['schema']` memberikan skema data yang dihasilkan oleh `SchemaGen` untuk memastikan bahwa transformasi data sesuai dengan aturan dan batasan skema.
   - `module_file=os.path.abspath(TRANSFORM_MODULE_FILE)` menentukan lokasi file modul Python yang berisi fungsi-fungsi transformasi data yang telah didefinisikan (dalam hal ini, file `sentiment_transform.py`).

2. **Menjalankan `Transform`**:
   - `interactive_context.run(transform)` menjalankan komponen `Transform` dalam konteks interaktif. Ini digunakan untuk transformasi data sesuai dengan modul yang diberikan dan skema yang ditetapkan, kemudian menyimpan hasilnya dalam direktori pipeline yang ditentukan (`PIPELINE_ROOT`).

# Modelling
"""

TRAINER_MODULE_FILE = "sentiment_trainer.py"

"""Variabel **`TRAINER_MODULE_FILE`** menetapkan nama file modul Python yang berisi kode untuk pelatihan model dalam pipeline TFX. Dalam hal ini, file yang dimaksud adalah `"sentiment_trainer.py"`."""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile {TRAINER_MODULE_FILE}
# import tensorflow as tf
# import tensorflow_transform as tft
# from tensorflow.keras import layers
# import os
# import tensorflow_hub as hub
# from tfx.components.trainer.fn_args_utils import FnArgs
# 
# LABEL_KEY = "sentiment"
# FEATURE_KEY = "review"
# 
# def transformed_name(key):
#     """Renaming transformed features"""
#     return key + "_xf"
# 
# def gzip_reader_fn(filenames):
#     """Loads compressed data"""
#     return tf.data.TFRecordDataset(filenames, compression_type='GZIP')
# 
# 
# def input_fn(file_pattern,
#              tf_transform_output,
#              num_epochs,
#              batch_size=64)->tf.data.Dataset:
#     """Get post_tranform feature & create batches of data"""
# 
#     # Get post_transform feature spec
#     transform_feature_spec = (
#         tf_transform_output.transformed_feature_spec().copy())
# 
#     # create batches of data
#     dataset = tf.data.experimental.make_batched_features_dataset(
#         file_pattern=file_pattern,
#         batch_size=batch_size,
#         features=transform_feature_spec,
#         reader=gzip_reader_fn,
#         num_epochs=num_epochs,
#         label_key = transformed_name(LABEL_KEY))
#     return dataset
# 
# # os.environ['TFHUB_CACHE_DIR'] = '/hub_chace'
# # embed = hub.KerasLayer("https://tfhub.dev/google/universal-sentence-encoder/4")
# 
# # Vocabulary size and number of words in a sequence.
# VOCAB_SIZE = 10000
# SEQUENCE_LENGTH = 100
# 
# vectorize_layer = layers.TextVectorization(
#     standardize="lower_and_strip_punctuation",
#     max_tokens=VOCAB_SIZE,
#     output_mode='int',
#     output_sequence_length=SEQUENCE_LENGTH)
# 
# 
# embedding_dim=16
# def model_builder():
#     """Build machine learning model"""
#     inputs = tf.keras.Input(shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string)
#     reshaped_narrative = tf.reshape(inputs, [-1])
#     x = vectorize_layer(reshaped_narrative)
#     x = layers.Embedding(VOCAB_SIZE, embedding_dim, name="embedding")(x)
#     x = layers.GlobalAveragePooling1D()(x)
#     x = layers.Dense(64, activation='relu')(x)
#     x = layers.Dense(32, activation="relu")(x)
#     outputs = layers.Dense(1, activation='sigmoid')(x)
# 
# 
#     model = tf.keras.Model(inputs=inputs, outputs = outputs)
# 
#     model.compile(
#         loss = 'binary_crossentropy',
#         optimizer=tf.keras.optimizers.Adam(0.01),
#         metrics=[tf.keras.metrics.BinaryAccuracy()]
# 
#     )
# 
#     # print(model)
#     model.summary()
#     return model
# 
# 
# def _get_serve_tf_examples_fn(model, tf_transform_output):
# 
#     model.tft_layer = tf_transform_output.transform_features_layer()
# 
#     @tf.function
#     def serve_tf_examples_fn(serialized_tf_examples):
# 
#         feature_spec = tf_transform_output.raw_feature_spec()
# 
#         feature_spec.pop(LABEL_KEY)
# 
#         parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)
# 
#         transformed_features = model.tft_layer(parsed_features)
# 
#         # get predictions using the transformed features
#         return model(transformed_features)
# 
#     return serve_tf_examples_fn
# 
# def run_fn(fn_args: FnArgs) -> None:
# 
#     log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')
# 
#     tensorboard_callback = tf.keras.callbacks.TensorBoard(
#         log_dir = log_dir, update_freq='batch'
#     )
# 
#     es = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=10)
#     mc = tf.keras.callbacks.ModelCheckpoint(fn_args.serving_model_dir, monitor='val_binary_accuracy', mode='max', verbose=1, save_best_only=True)
# 
# 
#     # Load the transform output
#     tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)
# 
#     # Create batches of data
#     train_set = input_fn(fn_args.train_files, tf_transform_output, 10)
#     val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)
#     vectorize_layer.adapt(
#         [j[0].numpy()[0] for j in [
#             i[0][transformed_name(FEATURE_KEY)]
#                 for i in list(train_set)]])
# 
#     # Build the model
#     model = model_builder()
# 
# 
#     # Train the model
#     model.fit(x = train_set,
#             validation_data = val_set,
#             callbacks = [tensorboard_callback, es, mc],
#             steps_per_epoch = 1000,
#             validation_steps= 1000,
#             epochs=10)
#     signatures = {
#         'serving_default':
#         _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(
#                                     tf.TensorSpec(
#                                     shape=[None],
#                                     dtype=tf.string,
#                                     name='examples'))
#     }
#     model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)

"""File **`sentiment_trainer.py`** berisi kode untuk pelatihan model machine learning dalam pipeline TFX. Berikut adalah deskripsi fungsi dan bagian utama dari kode ini:

1. **`transformed_name(key)`**:
   - Menambahkan suffix `"_xf"` pada nama fitur untuk menandakan bahwa fitur tersebut telah ditransformasi.

2. **`gzip_reader_fn(filenames)`**:
   - Membaca dataset TFRecord yang dikompresi dengan tipe kompresi 'GZIP'.

3. **`input_fn(file_pattern, tf_transform_output, num_epochs, batch_size)`**:
   - Menghasilkan dataset yang telah ditransformasi untuk pelatihan dan evaluasi dengan batching, menggunakan spesifikasi fitur yang dihasilkan dari transformasi.

4. **`vectorize_layer`**:
   - Layer `TextVectorization` untuk memproses teks, mengubahnya menjadi representasi integer yang dapat digunakan oleh model.

5. **`model_builder()`**:
   - Membangun dan mengkompilasi model Keras dengan arsitektur:
     - Input teks (dalam bentuk string).
     - Layer `TextVectorization` dan `Embedding`.
     - `GlobalAveragePooling1D`, dua layer Dense dengan aktivasi `relu`, dan output Dense dengan aktivasi `sigmoid`.
   - Menggunakan binary crossentropy sebagai fungsi loss dan binary accuracy sebagai metrik.

6. **`_get_serve_tf_examples_fn(model, tf_transform_output)`**:
   - Fungsi untuk menyajikan model dan transformasi fitur saat model di-deploy.
   - Menggunakan `tf.function` untuk mendefinisikan fungsi serve yang mengubah contoh yang diterima dan menghasilkan prediksi dari model.

7. **`run_fn(fn_args: FnArgs)`**:
   - Fungsi utama yang dipanggil oleh TFX Trainer:
     - Menyiapkan callback untuk TensorBoard, EarlyStopping, dan ModelCheckpoint.
     - Memuat output transformasi.
     - Membuat dataset untuk pelatihan dan evaluasi.
     - Menyesuaikan layer `TextVectorization` dengan data pelatihan.
     - Membangun dan melatih model dengan dataset yang disediakan.
     - Menyimpan model dengan signature untuk penyajian.

File ini mengatur proses pelatihan model dari awal hingga akhir, termasuk pemrosesan data, pelatihan model, dan penyimpanan model terlatih.
"""

from tfx.proto import trainer_pb2

trainer  = Trainer(
    module_file=os.path.abspath(TRAINER_MODULE_FILE),
    examples = transform.outputs['transformed_examples'],
    transform_graph=transform.outputs['transform_graph'],
    schema=schema_gen.outputs['schema'],
    train_args=trainer_pb2.TrainArgs(splits=['train']),
    eval_args=trainer_pb2.EvalArgs(splits=['eval'])
)
interactive_context.run(trainer)

"""Kode ini mengatur dan menjalankan komponen `Trainer` dalam pipeline TFX.

1. **Import `trainer_pb2`**:
   - Mengimpor modul protobuf yang berisi definisi untuk parameter pelatihan dan evaluasi.

2. **Membuat Instance `Trainer`**:
   - `module_file=os.path.abspath(TRAINER_MODULE_FILE)`: Menetapkan path absolut ke file modul Python yang berisi kode untuk pelatihan model (`sentiment_trainer.py`).
   - `examples=transform.outputs['transformed_examples']`: Menyediakan dataset yang telah ditransformasi oleh komponen `Transform` sebagai input untuk pelatihan.
   - `transform_graph=transform.outputs['transform_graph']`: Menyediakan grafik transformasi yang digunakan untuk menerapkan transformasi yang sama pada data pelatihan dan evaluasi.
   - `schema=schema_gen.outputs['schema']`: Menyediakan skema data yang dihasilkan oleh `SchemaGen` untuk memastikan konsistensi data.
   - `train_args=trainer_pb2.TrainArgs(splits=['train'])`: Menentukan bahwa data dari split `train` akan digunakan untuk pelatihan.
   - `eval_args=trainer_pb2.EvalArgs(splits=['eval'])`: Menentukan bahwa data dari split `eval` akan digunakan untuk evaluasi.

3. **Menjalankan `Trainer`**:
   - `interactive_context.run(trainer)`: Menjalankan komponen `Trainer` dalam konteks interaktif, memulai proses pelatihan model dengan dataset yang disediakan dan konfigurasi yang telah ditentukan.

Dengan kode ini, pipeline TFX akan melatih model berdasarkan data yang telah diproses dan dikonfigurasi, serta menyimpan model terlatih untuk digunakan dalam langkah-langkah selanjutnya.

# Analisis dan Validasi Model
"""

from tfx.dsl.components.common.resolver import Resolver
from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy
from tfx.types import Channel
from tfx.types.standard_artifacts import Model, ModelBlessing

model_resolver = Resolver(
    strategy_class= LatestBlessedModelStrategy,
    model = Channel(type=Model),
    model_blessing = Channel(type=ModelBlessing)
).with_id('Latest_blessed_model_resolver')

interactive_context.run(model_resolver)

"""Kode ini mengatur dan menjalankan komponen `Resolver` dalam pipeline TFX untuk memilih model terbaru. Berikut adalah penjelasan rinci dari setiap bagian:

1. **Import Statements**:
   - `from tfx.dsl.components.common.resolver import Resolver`: Mengimpor kelas `Resolver` dari TFX DSL, yang digunakan untuk memilih model yang memenuhi kriteria tertentu.
   - `from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy`: Mengimpor strategi pemilihan model yang memberkati model terbaru.
   - `from tfx.types import Channel`: Mengimpor kelas `Channel`, yang digunakan untuk mendefinisikan saluran data dalam TFX.
   - `from tfx.types.standard_artifacts import Model, ModelBlessing`: Mengimpor artefak standar yang digunakan dalam komponen `Resolver`, yaitu `Model` dan `ModelBlessing`.

2. **Membuat Instance `Resolver`**:
   - `strategy_class=LatestBlessedModelStrategy`: Menetapkan strategi pemilihan model yang akan digunakan, dalam hal ini, memilih model terbaru.
   - `model=Channel(type=Model)`: Menentukan saluran yang berisi model-model yang tersedia untuk dipilih.
   - `model_blessing=Channel(type=ModelBlessing)`: Menentukan saluran yang berisi informasi tentang model-model.
   - `.with_id('Latest_blessed_model_resolver')`: Memberikan ID pada instance `Resolver` untuk identifikasi di dalam pipeline.

3. **Menjalankan `Resolver`**:
   - `interactive_context.run(model_resolver)`: Menjalankan komponen `Resolver` dalam konteks interaktif, yang akan memilih model terbaru berdasarkan saluran yang disediakan.

Komponen ini membantu dalam mengidentifikasi model yang paling baru dan telah divalidasi dengan benar, memastikan bahwa model yang digunakan untuk langkah-langkah berikutnya adalah model yang sudah terbukti layak.
"""

import tensorflow_model_analysis as tfma

eval_config = tfma.EvalConfig(
    model_specs=[tfma.ModelSpec(label_key='sentiment')],
    slicing_specs=[tfma.SlicingSpec()],
    metrics_specs=[
        tfma.MetricsSpec(metrics=[

            tfma.MetricConfig(class_name='ExampleCount'),
            tfma.MetricConfig(class_name='AUC'),
            tfma.MetricConfig(class_name='FalsePositives'),
            tfma.MetricConfig(class_name='TruePositives'),
            tfma.MetricConfig(class_name='FalseNegatives'),
            tfma.MetricConfig(class_name='TrueNegatives'),
            tfma.MetricConfig(class_name='BinaryAccuracy',
                threshold=tfma.MetricThreshold(
                    value_threshold=tfma.GenericValueThreshold(
                        lower_bound={'value':0.5}),
                    change_threshold=tfma.GenericChangeThreshold(
                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,
                        absolute={'value':0.0001})
                    )
            )
        ])
    ]

)

"""Kode ini mengonfigurasi evaluasi model menggunakan TensorFlow Model Analysis (TFMA).

1. **Import Statement**:
   - `import tensorflow_model_analysis as tfma`: Mengimpor TensorFlow Model Analysis untuk menganalisis dan mengevaluasi performa model.

2. **Membuat Konfigurasi Evaluasi**:
   - `tfma.EvalConfig()`: Membuat konfigurasi evaluasi untuk model.

3. **Model Specifications**:
   - `model_specs=[tfma.ModelSpec(label_key='sentiment')]`: Menetapkan kunci label (`'sentiment'`) yang digunakan untuk evaluasi model. Ini memberi tahu TFMA tentang nama label yang harus digunakan untuk menghitung metrik evaluasi.

4. **Slicing Specifications**:
   - `slicing_specs=[tfma.SlicingSpec()]`: Menetapkan spesifikasi pemotongan (slicing) untuk evaluasi. Dalam hal ini, pemotongan tidak diatur secara spesifik, sehingga evaluasi dilakukan pada keseluruhan dataset.

5. **Metrics Specifications**:
   - `metrics_specs=[tfma.MetricsSpec(metrics=[ ... ])]`: Mendefinisikan metrik yang akan dihitung selama evaluasi model. Di sini, beberapa metrik disertakan:
     - `tfma.MetricConfig(class_name='ExampleCount')`: Menghitung jumlah contoh.
     - `tfma.MetricConfig(class_name='AUC')`: Menghitung Area Under the Curve (AUC) dari kurva ROC.
     - `tfma.MetricConfig(class_name='FalsePositives')`: Menghitung jumlah prediksi positif palsu.
     - `tfma.MetricConfig(class_name='TruePositives')`: Menghitung jumlah prediksi positif benar.
     - `tfma.MetricConfig(class_name='FalseNegatives')`: Menghitung jumlah prediksi negatif palsu.
     - `tfma.MetricConfig(class_name='TrueNegatives')`: Menghitung jumlah prediksi negatif benar.
     - `tfma.MetricConfig(class_name='BinaryAccuracy', ...)`: Menghitung akurasi biner dengan ambang batas dan perubahan threshold yang ditentukan. Akurasi dihitung hanya jika nilai ambang batas (`value_threshold`) lebih dari 0.5 dan perubahan minimal (`change_threshold`) lebih dari 0.0001.

Konfigurasi ini digunakan oleh TFMA untuk menganalisis performa model pada data evaluasi, menghitung berbagai metrik, dan memberikan informasi yang berguna tentang kualitas model.
"""

from tfx.components import Evaluator
evaluator = Evaluator(
    examples=example_gen.outputs['examples'],
    model=trainer.outputs['model'],
    baseline_model=model_resolver.outputs['model'],
    eval_config=eval_config)

interactive_context.run(evaluator)

"""Kode ini mengonfigurasi dan menjalankan komponen Evaluator dalam pipeline TFX untuk mengevaluasi performa model.

1. **Import Statement**:
   - `from tfx.components import Evaluator`: Mengimpor komponen Evaluator dari TFX yang digunakan untuk mengevaluasi model.

2. **Membuat Instance Evaluator**:
   - `evaluator = Evaluator(...)`: Membuat instance dari komponen Evaluator dengan parameter berikut:
     - `examples=example_gen.outputs['examples']`: Menggunakan output dari `example_gen` sebagai data contoh untuk evaluasi.
     - `model=trainer.outputs['model']`: Menetapkan model yang dilatih dari output `trainer` sebagai model yang akan dievaluasi.
     - `baseline_model=model_resolver.outputs['model']`: Menetapkan model dasar (baseline) dari output `model_resolver` untuk membandingkan performa model saat ini.
     - `eval_config=eval_config`: Menetapkan konfigurasi evaluasi yang telah ditentukan sebelumnya (`eval_config`) yang berisi spesifikasi metrik evaluasi.

3. **Menjalankan Evaluator**:
   - `interactive_context.run(evaluator)`: Menjalankan komponen Evaluator menggunakan `interactive_context`. Ini akan memulai proses evaluasi model berdasarkan konfigurasi yang telah disediakan, dan menghasilkan hasil evaluasi yang akan menunjukkan bagaimana performa model saat ini dibandingkan dengan model baseline.

Evaluator ini akan memberikan metrik evaluasi seperti AUC, akurasi, dan metrik lain yang telah didefinisikan dalam `eval_config`. Hasil evaluasi ini akan membantu dalam menilai kualitas model dan melakukan perbaikan jika diperlukan.
"""

# Visualize the evaluation results
eval_result = evaluator.outputs['evaluation'].get()[0].uri
tfma_result = tfma.load_eval_result(eval_result)
tfma.view.render_slicing_metrics(tfma_result)
tfma.addons.fairness.view.widget_view.render_fairness_indicator(
    tfma_result
)

"""Kode ini digunakan untuk memvisualisasikan hasil evaluasi model menggunakan TensorFlow Model Analysis (TFMA).

1. **Mendapatkan Hasil Evaluasi**:
   - `eval_result = evaluator.outputs['evaluation'].get()[0].uri`: Mengambil URI dari hasil evaluasi yang dihasilkan oleh komponen Evaluator. `evaluator.outputs['evaluation'].get()[0]` mengambil hasil evaluasi pertama, dan `.uri` mendapatkan URI dari file hasil evaluasi tersebut.

2. **Memuat Hasil Evaluasi**:
   - `tfma_result = tfma.load_eval_result(eval_result)`: Memuat hasil evaluasi dari file yang ditunjuk oleh URI menggunakan fungsi `tfma.load_eval_result()`. Hasil ini akan digunakan untuk analisis lebih lanjut.

3. **Menampilkan Metrik Slicing**:
   - `tfma.view.render_slicing_metrics(tfma_result)`: Menampilkan metrik evaluasi berdasarkan pemotongan (slicing) data.

4. **Menampilkan Indikator Keadilan**:
   - `tfma.addons.fairness.view.widget_view.render_fairness_indicator(tfma_result)`: Menampilkan indikator keadilan untuk menilai apakah model memiliki bias terhadap kelompok tertentu. Ini menggunakan addon fairness dari TFMA untuk visualisasi.

# Pusher
"""

from tfx.components import Pusher
from tfx.proto import pusher_pb2

pusher = Pusher(
model=trainer.outputs['model'],
model_blessing=evaluator.outputs['blessing'],
push_destination=pusher_pb2.PushDestination(
    filesystem=pusher_pb2.PushDestination.Filesystem(
        base_directory='serving_model_dir/sentiment-detection-model'))

)

interactive_context.run(pusher)

"""Kode ini digunakan untuk mendorong model yang telah dilatih dan dievaluasi ke lokasi penyimpanan yang ditentukan agar dapat digunakan untuk inferensi atau deployment.

1. **Pusher Component**:
   - `from tfx.components import Pusher`: Mengimpor komponen Pusher dari TFX, yang digunakan untuk menyimpan model ke lokasi penyimpanan yang ditentukan.

2. **Menyiapkan Pusher**:
   - `pusher = Pusher(`: Membuat instance dari komponen Pusher dengan parameter berikut:
     - `model=trainer.outputs['model']`: Menggunakan model yang dihasilkan dari komponen Trainer.
     - `model_blessing=evaluator.outputs['blessing']`: Menggunakan hasil blessing dari komponen Evaluator untuk memastikan model memenuhi kriteria kualitas sebelum didorong.
     - `push_destination=pusher_pb2.PushDestination(`: Menentukan tujuan penyimpanan model.
       - `filesystem=pusher_pb2.PushDestination.Filesystem(`: Mengatur tujuan penyimpanan ke sistem file lokal.
         - `base_directory='serving_model_dir/sentiment-detection-model'`: Menentukan direktori dasar di mana model akan disimpan.

3. **Menjalankan Pusher**:
   - `interactive_context.run(pusher)`: Menjalankan komponen Pusher untuk menyimpan model ke direktori yang telah ditentukan.

Dengan kode ini, model yang telah dilatih dan dievaluasi disimpan di `serving_model_dir/sentiment-detection-model`, siap digunakan untuk deployment atau inferensi lebih lanjut.
"""